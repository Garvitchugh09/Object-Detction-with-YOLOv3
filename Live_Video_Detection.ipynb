{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# Load Yolo\n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")  \n",
    "\n",
    "# dnn is deep neural network\n",
    "\n",
    "classes = []   \n",
    "\n",
    "# in classes you can specify objects that you want to detect \n",
    "\n",
    "# classes=['car','person','bicycle'] \n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:      \n",
    "\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "#print the name of classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading classes from coco file\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# with output layer we get detection of objects.\n",
    "\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret,img=video.read()\n",
    "    height, width, channels = img.shape\n",
    "    # Detecting objects\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    outs = net.forward(output_layers)\n",
    "    # Showing informations on the screen\n",
    "\n",
    "    class_ids = []\n",
    "\n",
    "    confidences = []\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "\n",
    "        for detection in out:\n",
    "\n",
    "            scores = detection[5:]\n",
    "\n",
    "            class_id = np.argmax(scores)\n",
    "\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "\n",
    "                # Object detected\n",
    "\n",
    "                center_x = int(detection[0] * width)\n",
    "\n",
    "                center_y = int(detection[1] * height)\n",
    "\n",
    "                w = int(detection[2] * width)\n",
    "\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    #print(indexes)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "\n",
    "        if i in indexes:\n",
    "\n",
    "            x, y, w, h = boxes[i]\n",
    "\n",
    "            label = str(classes[class_ids[i]])\n",
    "\n",
    "            color = colors[i]\n",
    "\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "            cv2.putText(img, label, (x, y + 30), font, 3, color, 2)    \n",
    "\n",
    "    #frame = cv2.resize(frame, None, fx=2, fy=2)\n",
    "    cv2.imshow(\"live cam\", img)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF==ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
